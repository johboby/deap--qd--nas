"""
QD-NASç¤ºä¾‹æ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨è´¨é‡-å¤šæ ·æ€§ç¥ç»æ¶æ„æœç´¢æ¡†æ¶
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.nas import (
    QDNASOptimizer, create_default_qd_nas,
    BehaviorSpace, SearchSpace, Architecture,
    StaticCharacterization, Objective, ObjectiveType, Constraint
)
import numpy as np


def example_1_basic_nas():
    """
    ç¤ºä¾‹1: åŸºç¡€NASæœç´¢

    ä½¿ç”¨MAP-Elitesç®—æ³•è¿›è¡Œå•ç›®æ ‡ä¼˜åŒ–
    """
    print("=" * 80)
    print("ç¤ºä¾‹1: åŸºç¡€NASæœç´¢ï¼ˆMAP-Elitesï¼‰")
    print("=" * 80)

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = create_default_qd_nas(
        optimization_mode='map_elites',
        multi_objective=False,
        population_guided=True
    )

    # åˆå§‹åŒ–
    print("\nğŸ“¦ åˆå§‹åŒ–ä¼˜åŒ–å™¨...")
    optimizer.initialize()

    # ä¼˜åŒ–
    print("\nğŸ”¥ å¼€å§‹ä¼˜åŒ–...")
    archive, pareto_front = optimizer.optimize(
        n_iterations=50,  # ä½¿ç”¨è¾ƒå°‘çš„è¿­ä»£ç”¨äºæ¼”ç¤º
        batch_size=20,
        verbose=True
    )

    # è·å–æœ€ä½³æ¶æ„
    print("\nğŸ“Š ä¼˜åŒ–ç»“æœ:")
    best_arch = optimizer.get_best_architecture()
    if best_arch:
        print(f"æœ€ä½³æ¶æ„:")
        arch_dict = best_arch.to_dict()
        print(f"  Cellæ•°é‡: {arch_dict['n_cells']}")
        print(f"  èŠ‚ç‚¹æ•°/Cell: {arch_dict['n_nodes']}")
        print(f"  åˆå§‹é€šé“æ•°: {arch_dict['n_channels']}")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = optimizer.get_statistics()
    print(f"\nå½’æ¡£ç»Ÿè®¡:")
    print(f"  å½’æ¡£å¤§å°: {stats['size']}")
    print(f"  è¡Œä¸ºç©ºé—´è¦†ç›–ç‡: {stats['coverage']:.2%}")
    print(f"  å¤šæ ·æ€§: {stats['diversity']:.4f}")

    print("\nâœ… ç¤ºä¾‹1å®Œæˆ")


def example_2_multi_objective():
    """
    ç¤ºä¾‹2: å¤šç›®æ ‡å¤šçº¦æŸä¼˜åŒ–

    ä¼˜åŒ–ç²¾åº¦ã€å»¶è¿Ÿå’Œèƒ½è€—ï¼ŒåŒæ—¶æ»¡è¶³çº¦æŸ
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹2: å¤šç›®æ ‡å¤šçº¦æŸä¼˜åŒ–")
    print("=" * 80)

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = create_default_qd_nas(
        optimization_mode='map_elites',
        multi_objective=True,
        population_guided=True
    )

    # åˆå§‹åŒ–
    print("\nğŸ“¦ åˆå§‹åŒ–ä¼˜åŒ–å™¨...")
    optimizer.initialize()

    # ä¼˜åŒ–
    print("\nğŸ”¥ å¼€å§‹å¤šç›®æ ‡ä¼˜åŒ–...")
    archive, pareto_front = optimizer.optimize(
        n_iterations=50,
        batch_size=20,
        verbose=True
    )

    # è·å–Paretoå‰æ²¿
    print("\nğŸ“Š Paretoå‰æ²¿:")
    pareto = optimizer.get_pareto_front()

    print(f"Paretoå‰æ²¿å¤§å°: {len(pareto)}")

    # æ˜¾ç¤ºå‰5ä¸ªè§£
    for i, (arch, metrics) in enumerate(pareto[:5]):
        print(f"\nè§£ {i+1}:")
        print(f"  ç²¾åº¦: {metrics.accuracy:.4f}")
        print(f"  å»¶è¿Ÿ: {metrics.latency:.2f} ms")
        print(f"  èƒ½è€—: {metrics.energy:.2f} mJ")
        print(f"  å‚æ•°é‡: {metrics.parameters:.2f} M")

        arch_dict = arch.to_dict()
        print(f"  Cellæ•°é‡: {arch_dict['n_cells']}")
        print(f"  åˆå§‹é€šé“æ•°: {arch_dict['n_channels']}")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = optimizer.get_statistics()
    print(f"\nå½’æ¡£ç»Ÿè®¡:")
    print(f"  å½’æ¡£å¤§å°: {stats['size']}")
    print(f"  Paretoå‰æ²¿å¤§å°: {stats.get('pareto_size', 0)}")

    print("\nâœ… ç¤ºä¾‹2å®Œæˆ")


def example_3_adaptive_search():
    """
    ç¤ºä¾‹3: è‡ªé€‚åº”æ··åˆæœç´¢

    ç»“åˆå¤šç§æœç´¢ç­–ç•¥ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹3: è‡ªé€‚åº”æ··åˆæœç´¢")
    print("=" * 80)

    # åˆ›å»ºä¼˜åŒ–å™¨ï¼Œä½¿ç”¨ä¸åŒçš„æœç´¢æ¨¡å¼
    optimizer = create_default_qd_nas(
        optimization_mode='random_map_elites',  # éšæœºæœç´¢å¢å¼º
        multi_objective=False,
        population_guided=True  # å¯ç”¨ç§ç¾¤å¼•å¯¼
    )

    # åˆå§‹åŒ–
    print("\nğŸ“¦ åˆå§‹åŒ–ä¼˜åŒ–å™¨...")
    optimizer.initialize()

    # ä¼˜åŒ–
    print("\nğŸ”¥ å¼€å§‹è‡ªé€‚åº”æœç´¢...")
    archive, pareto_front = optimizer.optimize(
        n_iterations=50,
        batch_size=20,
        verbose=True
    )

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = optimizer.get_statistics()

    print(f"\nğŸ“Š ä¼˜åŒ–ç»“æœ:")
    print(f"  å½’æ¡£å¤§å°: {stats['size']}")
    print(f"  è¡Œä¸ºç©ºé—´è¦†ç›–ç‡: {stats['coverage']:.2%}")
    print(f"  å¤šæ ·æ€§: {stats['diversity']:.4f}")

    if 'population_stats' in stats:
        pop_stats = stats['population_stats']
        print(f"\nç§ç¾¤ç»Ÿè®¡:")
        print(f"  å¹³å‡ç²¾åº¦: {pop_stats['mean_accuracy']:.4f}")
        print(f"  ç²¾åº¦æ ‡å‡†å·®: {pop_stats['std_accuracy']:.4f}")
        print(f"  ç§ç¾¤å¤šæ ·æ€§: {pop_stats['diversity']:.4f}")

    print("\nâœ… ç¤ºä¾‹3å®Œæˆ")


def example_4_custom_objectives():
    """
    ç¤ºä¾‹4: è‡ªå®šä¹‰ç›®æ ‡å‡½æ•°

    å®šä¹‰è‡ªå·±çš„ä¼˜åŒ–ç›®æ ‡å’Œçº¦æŸ
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹4: è‡ªå®šä¹‰ç›®æ ‡å‡½æ•°")
    print("=" * 80)

    from src.nas import MultiObjectiveNAS, Objective, Constraint

    # åˆ›å»ºæœç´¢ç©ºé—´å’Œç‰¹å¾æå–å™¨
    search_space = SearchSpace()
    characterizer = StaticCharacterization()
    behavior_space = BehaviorSpace()

    # å®šä¹‰ä¼˜åŒ–ç›®æ ‡
    objectives = [
        # ç²¾åº¦æœ€å¤§åŒ–
        Objective(name='accuracy', type=ObjectiveType.MAXIMIZE, weight=0.7),
        # å»¶è¿Ÿæœ€å°åŒ–
        Objective(name='latency', type=ObjectiveType.MINIMIZE, weight=0.2),
        # å‚æ•°é‡æœ€å°åŒ–
        Objective(name='params', type=ObjectiveType.MINIMIZE, weight=0.1),
    ]

    # å®šä¹‰çº¦æŸ
    constraints = [
        # å»¶è¿Ÿçº¦æŸ
        Constraint(name='latency', threshold=50.0, type="<="),
        # å‚æ•°é‡çº¦æŸ
        Constraint(name='params', threshold=3.0, type="<="),
    ]

    # åˆ›å»ºå¤šç›®æ ‡NASä¼˜åŒ–å™¨
    optimizer = MultiObjectiveNAS(
        behavior_space=behavior_space,
        characterizer=characterizer,
        objectives=objectives,
        constraints=constraints,
    )

    # ä¼˜åŒ–
    print("\nğŸ”¥ å¼€å§‹è‡ªå®šä¹‰ç›®æ ‡ä¼˜åŒ–...")
    archive, pareto_front = optimizer.evolve(
        generate_function=search_space.random_sample,
        mutate_function=search_space.mutate,
        n_iterations=50,
        batch_size=20,
        verbose=True
    )

    print(f"\nâœ… ä¼˜åŒ–å®Œæˆï¼ŒParetoå‰æ²¿å¤§å°: {len(pareto_front)}")

    print("\nâœ… ç¤ºä¾‹4å®Œæˆ")


def example_5_gradient_guided():
    """
    ç¤ºä¾‹5: æ¢¯åº¦å¼•å¯¼æœç´¢

    ä½¿ç”¨æ¢¯åº¦ä¿¡æ¯å¼•å¯¼æœç´¢æ–¹å‘
    """
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹5: æ¢¯åº¦å¼•å¯¼æœç´¢")
    print("=" * 80)

    # åˆ›å»ºä¼˜åŒ–å™¨ï¼Œä½¿ç”¨æ¢¯åº¦å¼•å¯¼
    optimizer = create_default_qd_nas(
        optimization_mode='gradient_map_elites',
        multi_objective=False,
        population_guided=True
    )

    # åˆå§‹åŒ–
    print("\nğŸ“¦ åˆå§‹åŒ–ä¼˜åŒ–å™¨...")
    optimizer.initialize()

    # ä¼˜åŒ–
    print("\nğŸ”¥ å¼€å§‹æ¢¯åº¦å¼•å¯¼æœç´¢...")
    archive, pareto_front = optimizer.optimize(
        n_iterations=50,
        batch_size=20,
        verbose=True
    )

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = optimizer.get_statistics()
    print(f"\nğŸ“Š ä¼˜åŒ–ç»“æœ:")
    print(f"  å½’æ¡£å¤§å°: {stats['size']}")
    print(f"  è¡Œä¸ºç©ºé—´è¦†ç›–ç‡: {stats['coverage']:.2%}")

    print("\nâœ… ç¤ºä¾‹5å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 80)
    print("QD-NAS: è´¨é‡-å¤šæ ·æ€§ç¥ç»æ¶æ„æœç´¢æ¡†æ¶")
    print("ç¤ºä¾‹æ¼”ç¤º")
    print("=" * 80)

    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    try:
        example_1_basic_nas()
        example_2_multi_objective()
        example_3_adaptive_search()
        example_4_custom_objectives()
        example_5_gradient_guided()

        print("\n" + "=" * 80)
        print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        print("=" * 80)

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
