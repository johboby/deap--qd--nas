"""
é«˜çº§QDç®—æ³• (Advanced QD Algorithms)
å®ç°CVT-MAP-Eliteså’ŒDiverse Qualityç®—æ³•
"""

import numpy as np
from typing import List, Dict, Any, Optional, Callable, Tuple
import logging
from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist

from .behavior_space import BehaviorSpace
from .archive import Archive, ArchiveEntry
from .characterization import ArchitectureMetrics, BaseCharacterization


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CVTMAPElites:
    """
    CVT-MAP-Elites (Centroidal Voronoi Tessellation MAP-Elites)

    ä½¿ç”¨CVTåˆ’åˆ†è¡Œä¸ºç©ºé—´ï¼Œæä¾›æ›´å‡åŒ€çš„è§£åˆ†å¸ƒã€‚

    æ ¸å¿ƒç‰¹æ€§:
    1. CVTåˆ’åˆ†è¡Œä¸ºç©ºé—´
    2. æ¯ä¸ªVoronoiå•å…ƒä¿å­˜æœ€ä½³ä¸ªä½“
    3. æ›´å¥½çš„ç©ºé—´è¦†ç›–
    4. æ›´é«˜æ•ˆçš„å¤šæ ·æ€§ç»´æŠ¤

    å‚è€ƒæ–‡çŒ®:
    Vassiliades, V., et al. (2020). Using centroidal voronoi tessellations to scale
    up the multidimensional archive of phenotypic elites algorithm. IEEE TEC.
    """

    def __init__(self,
                 behavior_space: BehaviorSpace,
                 characterizer: BaseCharacterization,
                 n_cells: int = 1000,
                 optimize_for: str = 'accuracy',
                 batch_size: int = 100):
        """
        åˆå§‹åŒ–CVT-MAP-Elites

        Args:
            behavior_space: è¡Œä¸ºç©ºé—´å®šä¹‰
            characterizer: ç‰¹å¾æå–å™¨
            n_cells: CVTå•å…ƒæ•°é‡
            optimize_for: ä¼˜åŒ–ç›®æ ‡
            batch_size: æ‰¹å¤„ç†å¤§å°
        """
        self.behavior_space = behavior_space
        self.characterizer = characterizer
        self.n_cells = n_cells
        self.optimize_for = optimize_for
        self.batch_size = batch_size

        # CVT centroids
        self.centroids = None

        # å½’æ¡£: {cell_index: ArchiveEntry}
        self.archive: Dict[int, ArchiveEntry] = {}

        # æ€§èƒ½è·Ÿè¸ª
        self.best_fitness = -np.inf
        self.best_architecture = None

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_insertions = 0
        self.total_rejections = 0

        # åˆå§‹åŒ–CVT
        self._initialize_cvt()

        logger.info(f"ğŸ—ºï¸  CVT-MAP-Elitesåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   CVTå•å…ƒæ•°: {n_cells}")

    def _initialize_cvt(self):
        """åˆå§‹åŒ–CVT centroids"""
        logger.info("ğŸ”„ åˆå§‹åŒ–CVT centroids")

        # ç”Ÿæˆéšæœºé‡‡æ ·ç‚¹
        n_samples = self.n_cells * 100
        samples = []

        for _ in range(n_samples):
            # ç”Ÿæˆéšæœºè¡Œä¸ºå‘é‡
            behavior_vector = []
            for dim in self.behavior_space.dimensions:
                value = np.random.uniform(dim.min_val, dim.max_val)
                behavior_vector.append(value)

            samples.append(behavior_vector)

        samples = np.array(samples)

        # K-meansèšç±»
        kmeans = KMeans(n_clusters=self.n_cells, random_state=42, n_init=10)
        self.centroids = kmeans.fit_predict(samples, sample_weight=None)
        self.centroids = kmeans.cluster_centers_

        logger.info(f"âœ… CVT centroidsåˆå§‹åŒ–å®Œæˆ")

    def _get_cell_index(self, behavior_vector: List[float]) -> int:
        """
        è·å–è¡Œä¸ºå‘é‡å¯¹åº”çš„cellç´¢å¼•

        Args:
            behavior_vector: è¡Œä¸ºç‰¹å¾å‘é‡

        Returns:
            CVT cellç´¢å¼•
        """
        # è®¡ç®—åˆ°æ‰€æœ‰centroidsçš„è·ç¦»
        distances = cdist([behavior_vector], self.centroids, 'euclidean')
        cell_index = np.argmin(distances[0])

        return cell_index

    def _get_fitness(self, metrics: ArchitectureMetrics) -> float:
        """è·å–é€‚åº”åº¦å€¼"""
        if self.optimize_for == 'accuracy':
            return metrics.accuracy
        elif self.optimize_for == 'latency':
            return -metrics.latency
        elif self.optimize_for == 'energy':
            return -metrics.energy
        else:
            return metrics.accuracy

    def insert(self,
              architecture: Any,
              metrics: ArchitectureMetrics,
              generation: int = 0) -> bool:
        """
        æ’å…¥ä¸€ä¸ªæ¶æ„åˆ°å½’æ¡£

        Args:
            architecture: æ¶æ„è¡¨ç¤º
            metrics: æ€§èƒ½æŒ‡æ ‡
            generation: å‘ç°ä»£æ•°

        Returns:
            æ˜¯å¦æˆåŠŸæ’å…¥
        """
        # è·å–è¡Œä¸ºç‰¹å¾
        behavior_vector = metrics.get_behavior_vector()

        # è·å–cellç´¢å¼•
        cell_index = self._get_cell_index(behavior_vector)

        # è·å–é€‚åº”åº¦
        fitness = self._get_fitness(metrics)

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’å…¥
        should_insert = False

        if cell_index not in self.archive:
            # Cellä¸ºç©ºï¼Œç›´æ¥æ’å…¥
            should_insert = True
        else:
            # Cellå·²æœ‰ä¸ªä½“ï¼Œæ¯”è¾ƒæ€§èƒ½
            current_fitness = self._get_fitness(self.archive[cell_index].metrics)
            if fitness > current_fitness:
                should_insert = True

        if should_insert:
            # åˆ›å»ºå½’æ¡£æ¡ç›®
            entry = ArchiveEntry(
                architecture=architecture,
                metrics=metrics,
                behavior_vector=behavior_vector,
                cell_key=(cell_index,),  # CVTç”¨å•ä¸ªç´¢å¼•ä½œä¸ºkey
                generation=generation
            )

            # æ’å…¥å½’æ¡£
            self.archive[cell_index] = entry
            self.total_insertions += 1

            # æ›´æ–°æœ€ä½³ä¸ªä½“
            if fitness > self.best_fitness:
                self.best_fitness = fitness
                self.best_architecture = architecture

            return True
        else:
            self.total_rejections += 1
            return False

    def evolve(self,
              generate_function: Callable,
              mutate_function: Callable,
              n_iterations: int = 1000,
              verbose: bool = True) -> Archive:
        """
        è¿è¡ŒCVT-MAP-Elitesè¿›åŒ–

        Args:
            generate_function: ç”Ÿæˆå‡½æ•°
            mutate_function: å˜å¼‚å‡½æ•°
            n_iterations: è¿­ä»£æ¬¡æ•°
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯

        Returns:
            å½’æ¡£å¯¹è±¡
        """
        logger.info(f"ğŸš€ å¼€å§‹CVT-MAP-Elitesè¿›åŒ–ï¼Œè¿­ä»£æ¬¡æ•°: {n_iterations}")

        for iteration in range(n_iterations):
            # ç”Ÿæˆä¸€æ‰¹æ–°ä¸ªä½“
            batch = []
            for _ in range(self.batch_size):
                # ä»å½’æ¡£ä¸­éšæœºé€‰æ‹©çˆ¶ä»£
                if self.archive and np.random.random() < 0.9:
                    parent = np.random.choice(list(self.archive.values()))
                    child = mutate_function(parent.architecture)
                else:
                    child = generate_function()

                batch.append(child)

            # è¯„ä¼°å¹¶æ’å…¥å½’æ¡£
            inserted_count = 0
            for arch in batch:
                metrics = self.characterizer.characterize(arch)
                if self.insert(arch, metrics, generation=iteration):
                    inserted_count += 1

            # è¾“å‡ºè¿›åº¦
            if verbose and (iteration + 1) % 10 == 0:
                stats = self.get_statistics()
                logger.info(
                    f"Iteration {iteration + 1}/{n_iterations} | "
                    f"Archive: {stats['size']} | "
                    f"Coverage: {stats['coverage']:.2%} | "
                    f"Best: {stats['best_fitness']:.4f}"
                )

        logger.info("âœ… CVT-MAP-Elitesè¿›åŒ–å®Œæˆ")

        # è¿”å›å½’æ¡£ï¼ˆè½¬æ¢ä¸ºæ ‡å‡†Archiveå¯¹è±¡ï¼‰
        return self._convert_to_archive()

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.archive:
            return {
                'size': 0,
                'coverage': 0.0,
                'best_fitness': -np.inf,
            }

        entries = list(self.archive.values())

        # è®¡ç®—å¤šæ ·æ€§
        behavior_vectors = [e.behavior_vector for e in entries]
        vectors = np.array(behavior_vectors)

        diversity = 0.0
        if len(vectors) > 1:
            distances = cdist(vectors, vectors, 'euclidean')
            diversity = np.mean(distances[distances > 0])

        return {
            'size': len(self.archive),
            'coverage': len(self.archive) / self.n_cells,
            'diversity': float(diversity),
            'best_fitness': self.best_fitness,
            'total_insertions': self.total_insertions,
            'total_rejections': self.total_rejections,
        }

    def _convert_to_archive(self) -> Archive:
        """è½¬æ¢ä¸ºæ ‡å‡†Archiveå¯¹è±¡"""
        archive = Archive(
            behavior_space=self.behavior_space,
            optimize_for=self.optimize_for
        )

        for entry in self.archive.values():
            archive.insert(
                architecture=entry.architecture,
                metrics=entry.metrics,
                generation=entry.generation
            )

        return archive


class DiverseQualityArchive:
    """
    Diverse Quality Archive (DQ-Archive)

    åŒæ—¶è€ƒè™‘è´¨é‡å’Œå¤šæ ·æ€§çš„å½’æ¡£æ–¹æ³•ã€‚

    æ ¸å¿ƒç‰¹æ€§:
    1. åŸºäºè´¨é‡çš„æ’åº
    2. åŸºäºå¤šæ ·æ€§çš„æ’åº
    3. å¹³è¡¡è´¨é‡å’Œå¤šæ ·æ€§
    4. è‡ªé€‚åº”é€‰æ‹©ç­–ç•¥
    """

    def __init__(self,
                 behavior_space: BehaviorSpace,
                 optimize_for: str = 'accuracy',
                 max_size: int = 100,
                 diversity_weight: float = 0.5):
        """
        åˆå§‹åŒ–DQå½’æ¡£

        Args:
            behavior_space: è¡Œä¸ºç©ºé—´å®šä¹‰
            optimize_for: ä¼˜åŒ–ç›®æ ‡
            max_size: æœ€å¤§å½’æ¡£å¤§å°
            diversity_weight: å¤šæ ·æ€§æƒé‡ [0, 1]
        """
        self.behavior_space = behavior_space
        self.optimize_for = optimize_for
        self.max_size = max_size
        self.diversity_weight = diversity_weight

        # å½’æ¡£åˆ—è¡¨
        self.entries: List[ArchiveEntry] = []

        # è´¨é‡å’Œå¤šæ ·æ€§åˆ†æ•°ç¼“å­˜
        self._quality_scores = {}
        self._diversity_scores = {}

        logger.info(f"ğŸ¯ DQå½’æ¡£åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æœ€å¤§å¤§å°: {max_size}")
        logger.info(f"   å¤šæ ·æ€§æƒé‡: {diversity_weight}")

    def _compute_quality_score(self, metrics: ArchitectureMetrics) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        if self.optimize_for == 'accuracy':
            return metrics.accuracy
        elif self.optimize_for == 'latency':
            # å½’ä¸€åŒ–åˆ°[0, 1]
            return max(0, 1 - metrics.latency / 1000)
        elif self.optimize_for == 'energy':
            return max(0, 1 - metrics.energy / 1000)
        else:
            return metrics.accuracy

    def _compute_diversity_score(self, behavior_vector: List[float]) -> float:
        """è®¡ç®—å¤šæ ·æ€§åˆ†æ•°"""
        if not self.entries:
            return 1.0

        # è®¡ç®—åˆ°æœ€è¿‘é‚»å±…çš„è·ç¦»
        distances = []
        for entry in self.entries:
            dist = self.behavior_space.distance(behavior_vector, entry.behavior_vector)
            distances.append(dist)

        # ä½¿ç”¨åˆ°æœ€è¿‘é‚»å±…çš„è·ç¦»ä½œä¸ºå¤šæ ·æ€§åˆ†æ•°
        min_distance = min(distances)
        return min(min_distance, 1.0)

    def insert(self,
              architecture: Any,
              metrics: ArchitectureMetrics,
              generation: int = 0) -> bool:
        """
        æ’å…¥ä¸€ä¸ªæ¶æ„åˆ°å½’æ¡£

        Args:
            architecture: æ¶æ„è¡¨ç¤º
            metrics: æ€§èƒ½æŒ‡æ ‡
            generation: å‘ç°ä»£æ•°

        Returns:
            æ˜¯å¦æˆåŠŸæ’å…¥
        """
        # è·å–è¡Œä¸ºç‰¹å¾
        behavior_vector = metrics.get_behavior_vector()

        # è®¡ç®—è´¨é‡åˆ†æ•°
        quality_score = self._compute_quality_score(metrics)

        # è®¡ç®—å¤šæ ·æ€§åˆ†æ•°
        diversity_score = self._compute_diversity_score(behavior_vector)

        # ç»¼åˆåˆ†æ•°
        combined_score = (1 - self.diversity_weight) * quality_score + \
                        self.diversity_weight * diversity_score

        # åˆ›å»ºå½’æ¡£æ¡ç›®
        entry = ArchiveEntry(
            architecture=architecture,
            metrics=metrics,
            behavior_vector=behavior_vector,
            cell_key=(),  # DQä¸ä½¿ç”¨ç½‘æ ¼
            generation=generation
        )

        # å¦‚æœå½’æ¡£æœªæ»¡ï¼Œç›´æ¥æ’å…¥
        if len(self.entries) < self.max_size:
            self.entries.append(entry)
            self._quality_scores[entry] = quality_score
            self._diversity_scores[entry] = diversity_score
            return True

        # å¦‚æœå½’æ¡£å·²æ»¡ï¼Œæ›¿æ¢ç»¼åˆåˆ†æ•°æœ€ä½çš„
        min_combined_score = float('inf')
        min_entry = None

        for e in self.entries:
            q_score = self._quality_scores[e]
            d_score = self._diversity_scores[e]
            combined = (1 - self.diversity_weight) * q_score + \
                       self.diversity_weight * d_score

            if combined < min_combined_score:
                min_combined_score = combined
                min_entry = e

        if combined_score > min_combined_score:
            # æ›¿æ¢
            self.entries.remove(min_entry)
            del self._quality_scores[min_entry]
            del self._diversity_scores[min_entry]

            self.entries.append(entry)
            self._quality_scores[entry] = quality_score
            self._diversity_scores[entry] = diversity_score
            return True

        return False

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.entries:
            return {
                'size': 0,
                'mean_quality': 0.0,
                'mean_diversity': 0.0,
            }

        mean_quality = np.mean(list(self._quality_scores.values()))
        mean_diversity = np.mean(list(self._diversity_scores.values()))

        return {
            'size': len(self.entries),
            'mean_quality': float(mean_quality),
            'mean_diversity': float(mean_diversity),
        }

    def get_entries(self) -> List[ArchiveEntry]:
        """è·å–æ‰€æœ‰æ¡ç›®"""
        return self.entries.copy()


def create_cvt_map_elites(behavior_space: BehaviorSpace,
                         characterizer: BaseCharacterization,
                         n_cells: int = 1000,
                         **kwargs) -> CVTMAPElites:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºCVT-MAP-Elitesä¼˜åŒ–å™¨

    Args:
        behavior_space: è¡Œä¸ºç©ºé—´å®šä¹‰
        characterizer: ç‰¹å¾æå–å™¨
        n_cells: CVTå•å…ƒæ•°é‡
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        CVT-MAP-Elitesä¼˜åŒ–å™¨
    """
    return CVTMAPElites(
        behavior_space=behavior_space,
        characterizer=characterizer,
        n_cells=n_cells,
        **kwargs
    )


def create_dq_archive(behavior_space: BehaviorSpace,
                     max_size: int = 100,
                     diversity_weight: float = 0.5,
                     **kwargs) -> DiverseQualityArchive:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºDQå½’æ¡£

    Args:
        behavior_space: è¡Œä¸ºç©ºé—´å®šä¹‰
        max_size: æœ€å¤§å½’æ¡£å¤§å°
        diversity_weight: å¤šæ ·æ€§æƒé‡
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        DQå½’æ¡£
    """
    return DiverseQualityArchive(
        behavior_space=behavior_space,
        max_size=max_size,
        diversity_weight=diversity_weight,
        **kwargs
    )


__all__ = [
    'CVTMAPElites',
    'DiverseQualityArchive',
    'create_cvt_map_elites',
    'create_dq_archive',
]
