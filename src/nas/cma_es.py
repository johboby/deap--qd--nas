"""
çœŸæ­£çš„CMA-ESç®—æ³•å®ç°
Covariance Matrix Adaptation Evolution Strategy
ç”¨äºQD-NASçš„é«˜æ•ˆä¼˜åŒ–
"""

import numpy as np
from typing import List, Tuple, Callable, Optional, Dict, Any
import logging
from dataclasses import dataclass


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class CMAParameters:
    """
    CMA-ESå‚æ•°é…ç½®

    Args:
        population_size: ç§ç¾¤å¤§å°
        sigma: åˆå§‹æ­¥é•¿
        sigma_decay: æ­¥é•¿è¡°å‡ç‡
        ccum: åæ–¹å·®çŸ©é˜µç´¯ç§¯æƒé‡
        cs: æ­¥é•¿æ§åˆ¶ç´¯ç§¯æƒé‡
        c1: åæ–¹å·®çŸ©é˜µæ›´æ–°æƒé‡ï¼ˆç§©1ï¼‰
        cmu: åæ–¹å·®çŸ©é˜µæ›´æ–°æƒé‡ï¼ˆç§©Î¼ï¼‰
        damps: æ­¥é•¿æ§åˆ¶é˜»å°¼å› å­
    """
    population_size: int = 50
    sigma: float = 0.5
    sigma_decay: float = 0.95
    ccum: float = 0.5
    cs: float = 0.5
    c1: float = 0.3
    cmu: float = 0.3
    damps: float = 1.0

    def __post_init__(self):
        """éªŒè¯å‚æ•°"""
        assert self.population_size > 0, "population_size must be positive"
        assert self.sigma > 0, "sigma must be positive"
        assert 0 < self.ccum < 1, "ccum must be in (0, 1)"
        assert 0 < self.cs < 1, "cs must be in (0, 1)"
        assert 0 < self.c1 < 1, "c1 must be in (0, 1)"
        assert 0 < self.cmu < 1, "cmu must be in (0, 1)"
        assert self.damps > 0, "damps must be positive"


class CMAESOptimizer:
    """
    CMA-ESä¼˜åŒ–å™¨

    Covariance Matrix Adaptation Evolution Strategy
    è‡ªé€‚åº”åæ–¹å·®çŸ©é˜µè¿›åŒ–ç­–ç•¥ï¼Œç”¨äºè¿ç»­ä¼˜åŒ–é—®é¢˜ã€‚

    æ ¸å¿ƒç‰¹æ€§:
    1. è‡ªé€‚åº”æ­¥é•¿æ§åˆ¶
    2. åæ–¹å·®çŸ©é˜µå­¦ä¹ 
    3. ç§©1å’Œç§©Î¼æ›´æ–°
    4. ç²¾è‹±é€‰æ‹©

    å‚è€ƒæ–‡çŒ®:
    Hansen, N., & Ostermeier, A. (2001). Completely derandomized self-adaptation
    in evolution strategies. Evolutionary Computation, 9(2), 159-195.
    """

    def __init__(self,
                 dimension: int,
                 objective_function: Callable[[np.ndarray], float],
                 params: Optional[CMAParameters] = None,
                 x0: Optional[np.ndarray] = None):
        """
        åˆå§‹åŒ–CMA-ES

        Args:
            dimension: ä¼˜åŒ–ç»´åº¦
            objective_function: ç›®æ ‡å‡½æ•°
            params: CMA-ESå‚æ•°ï¼ˆå¯é€‰ï¼‰
            x0: åˆå§‹è§£ï¼ˆå¯é€‰ï¼Œé»˜è®¤éšæœºï¼‰
        """
        self.dimension = dimension
        self.objective_function = objective_function
        self.params = params or CMAParameters()

        # åˆå§‹åŒ–å‡å€¼
        self.mean = x0 if x0 is not None else np.random.randn(dimension)

        # åˆå§‹åŒ–åæ–¹å·®çŸ©é˜µ
        self.C = np.eye(dimension)

        # åˆå§‹åŒ–æ­¥é•¿
        self.sigma = self.params.sigma

        # è¿›åŒ–è·¯å¾„
        self.pc = np.zeros(dimension)  # åæ–¹å·®çŸ©é˜µè¿›åŒ–è·¯å¾„
        self.ps = np.zeros(dimension)  # æ­¥é•¿è¿›åŒ–è·¯å¾„

        # æƒé‡è®¾ç½®
        self.mu = int(self.params.population_size / 2)
        self.weights = self._compute_weights(self.mu)

        # é¢„è®¡ç®—å‚æ•°
        self.mueff = 1 / np.sum(self.weights**2)
        self.ccum_cov = 4 / (self.dimension + 4)
        self.ccum_sigma = 4 / (self.dimension + 4)

        # æœŸæœ›å€¼
        self.chiN = np.sqrt(self.dimension) * (1 - 1/(4*self.dimension) + 1/(21*self.dimension**2))

        # å†å²è®°å½•
        self.best_fitness_history = []
        self.mean_fitness_history = []
        self.sigma_history = []

        logger.info(f"ğŸ§¬ CMA-ESä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   ç»´åº¦: {dimension}")
        logger.info(f"   ç§ç¾¤å¤§å°: {self.params.population_size}")
        logger.info(f"   åˆå§‹æ­¥é•¿: {self.sigma}")

    def _compute_weights(self, mu: int) -> np.ndarray:
        """
        è®¡ç®—é‡ç»„æƒé‡

        Args:
            mu: é€‰æ‹©çš„ç²¾è‹±æ•°é‡

        Returns:
            æƒé‡æ•°ç»„
        """
        # å¯¹æ•°æƒé‡
        weights = np.log(mu + 1) - np.log(np.arange(1, mu + 1))
        weights = weights / np.sum(weights)

        return weights

    def _sample_population(self) -> np.ndarray:
        """
        é‡‡æ ·ç§ç¾¤

        Returns:
            (population_size, dimension) çš„ç§ç¾¤çŸ©é˜µ
        """
        # Choleskyåˆ†è§£åæ–¹å·®çŸ©é˜µ
        try:
            B = np.linalg.cholesky(self.C)
        except np.linalg.LinAlgError:
            # å¦‚æœä¸æ˜¯æ­£å®šçš„ï¼Œæ·»åŠ å°çš„å¯¹è§’æ‰°åŠ¨
            self.C += np.eye(self.dimension) * 1e-12
            B = np.linalg.cholesky(self.C)

        # é‡‡æ ·
        z = np.random.randn(self.params.population_size, self.dimension)
        population = self.mean + self.sigma * (B @ z.T).T

        return population

    def _evaluate_population(self, population: np.ndarray) -> np.ndarray:
        """
        è¯„ä¼°ç§ç¾¤

        Args:
            population: ç§ç¾¤çŸ©é˜µ

        Returns:
            é€‚åº”åº¦æ•°ç»„
        """
        fitness = np.array([self.objective_function(ind) for ind in population])
        return fitness

    def _sort_and_select(self, population: np.ndarray, fitness: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ’åºå¹¶é€‰æ‹©ç²¾è‹±

        Args:
            population: ç§ç¾¤çŸ©é˜µ
            fitness: é€‚åº”åº¦æ•°ç»„

        Returns:
            (selected_population, selected_fitness)
        """
        # æ’åºï¼ˆæ ¹æ®é€‚åº”åº¦ï¼‰
        sorted_indices = np.argsort(fitness)
        selected_indices = sorted_indices[:self.mu]

        selected_population = population[selected_indices]
        selected_fitness = fitness[selected_indices]

        return selected_population, selected_fitness

    def _update_mean(self, selected_population: np.ndarray):
        """
        æ›´æ–°å‡å€¼

        Args:
            selected_population: é€‰æ‹©çš„ç²¾è‹±ç§ç¾¤
        """
        # åŠ æƒå¹³å‡
        self.mean = np.sum(self.weights[:, np.newaxis] * selected_population, axis=0)

    def _update_evolution_path(self, old_mean: np.ndarray, selected_population: np.ndarray):
        """
        æ›´æ–°è¿›åŒ–è·¯å¾„

        Args:
            old_mean: æ—§å‡å€¼
            selected_population: é€‰æ‹©çš„ç²¾è‹±ç§ç¾¤
        """
        # è®¡ç®—åŠ æƒå¹³å‡çš„å˜å¼‚
        yw = np.sum(self.weights[:, np.newaxis] * (selected_population - old_mean), axis=0)

        # æ›´æ–°æ­¥é•¿è¿›åŒ–è·¯å¾„
        self.ps = (1 - self.params.cs) * self.ps + \
                  np.sqrt(self.cs * (2 - self.cs) * self.mueff) * yw / self.sigma

        # æ›´æ–°åæ–¹å·®è¿›åŒ–è·¯å¾„
        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.params.cs)**(2 * len(self.best_fitness_history))) < (1.4 + 2 / (self.dimension + 1))
        self.pc = (1 - self.params.ccum) * self.pc + hsig * np.sqrt(self.params.ccum * (2 - self.params.ccum) * self.mueff) * yw / self.sigma

    def _update_covariance(self, selected_population: np.ndarray):
        """
        æ›´æ–°åæ–¹å·®çŸ©é˜µ

        Args:
            selected_population: é€‰æ‹©çš„ç²¾è‹±ç§ç¾¤
        """
        # ç§©1æ›´æ–°
        rank_one_update = np.outer(self.pc, self.pc)

        # ç§©Î¼æ›´æ–°
        z = (selected_population - self.mean) / self.sigma
        rank_mu_update = np.sum([self.weights[i] * np.outer(z[i], z[i]) for i in range(len(self.weights))], axis=0)

        # ç»„åˆæ›´æ–°
        self.C = (1 - self.params.c1 - self.params.cmu) * self.C + \
                 self.params.c1 * rank_one_update + \
                 self.params.cmu * rank_mu_update

    def _update_step_size(self):
        """æ›´æ–°æ­¥é•¿"""
        # è®¡ç®—æ­¥é•¿æ›´æ–°å› å­
        sigma_update = np.exp((self.cs / self.params.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))

        # æ›´æ–°æ­¥é•¿
        self.sigma *= sigma_update

        # åº”ç”¨è¡°å‡ï¼ˆå¯é€‰ï¼‰
        if self.params.sigma_decay < 1.0:
            self.sigma *= self.params.sigma_decay

    def step(self) -> Tuple[np.ndarray, float]:
        """
        æ‰§è¡Œä¸€æ­¥CMA-ESè¿­ä»£

        Returns:
            (best_individual, best_fitness)
        """
        old_mean = self.mean.copy()

        # é‡‡æ ·ç§ç¾¤
        population = self._sample_population()

        # è¯„ä¼°ç§ç¾¤
        fitness = self._evaluate_population(population)

        # é€‰æ‹©ç²¾è‹±
        selected_population, selected_fitness = self._sort_and_select(population, fitness)

        # æ›´æ–°å‡å€¼
        self._update_mean(selected_population)

        # æ›´æ–°è¿›åŒ–è·¯å¾„
        self._update_evolution_path(old_mean, selected_population)

        # æ›´æ–°åæ–¹å·®çŸ©é˜µ
        self._update_covariance(selected_population)

        # æ›´æ–°æ­¥é•¿
        self._update_step_size()

        # è®°å½•å†å²
        best_fitness = np.min(fitness)
        mean_fitness = np.mean(fitness)
        self.best_fitness_history.append(best_fitness)
        self.mean_fitness_history.append(mean_fitness)
        self.sigma_history.append(self.sigma)

        # è¿”å›æœ€ä½³ä¸ªä½“
        best_index = np.argmin(fitness)
        return population[best_index], best_fitness

    def optimize(self,
                 n_iterations: int = 1000,
                 verbose: bool = True) -> Tuple[np.ndarray, float, Dict[str, Any]]:
        """
        è¿è¡ŒCMA-ESä¼˜åŒ–

        Args:
            n_iterations: è¿­ä»£æ¬¡æ•°
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯

        Returns:
            (best_solution, best_fitness, info)
        """
        logger.info(f"ğŸš€ å¼€å§‹CMA-ESä¼˜åŒ–ï¼Œè¿­ä»£æ¬¡æ•°: {n_iterations}")

        best_solution = None
        best_fitness = np.inf

        for iteration in range(n_iterations):
            # æ‰§è¡Œä¸€æ­¥è¿­ä»£
            solution, fitness = self.step()

            # æ›´æ–°æœ€ä½³è§£
            if fitness < best_fitness:
                best_fitness = fitness
                best_solution = solution.copy()

            # è¾“å‡ºè¿›åº¦
            if verbose and (iteration + 1) % 10 == 0:
                logger.info(
                    f"Iteration {iteration + 1}/{n_iterations} | "
                    f"Best: {best_fitness:.6f} | "
                    f"Mean: {self.mean_fitness_history[-1]:.6f} | "
                    f"Sigma: {self.sigma:.6f}"
                )

        logger.info("âœ… CMA-ESä¼˜åŒ–å®Œæˆ")

        # è¿”å›ç»“æœ
        info = {
            'best_fitness_history': self.best_fitness_history,
            'mean_fitness_history': self.mean_fitness_history,
            'sigma_history': self.sigma_history,
            'final_mean': self.mean,
            'final_sigma': self.sigma,
            'iterations': n_iterations,
        }

        return best_solution, best_fitness, info


class CMAESOptimizerQD:
    """
    CMA-ESä¼˜åŒ–å™¨ç”¨äºQD-NAS

    å°†CMA-ESä¸QDæ¡†æ¶ç»“åˆï¼Œæ”¯æŒè¡Œä¸ºç©ºé—´æ˜ å°„å’Œå¤šæ ·æ€§ç»´æŠ¤ã€‚
    """

    def __init__(self,
                 dimension: int,
                 behavior_function: Callable[[np.ndarray], List[float]],
                 objective_function: Callable[[np.ndarray], float],
                 behavior_space,
                 params: Optional[CMAParameters] = None):
        """
        åˆå§‹åŒ–CMA-ES QDä¼˜åŒ–å™¨

        Args:
            dimension: ä¼˜åŒ–ç»´åº¦
            behavior_function: è¡Œä¸ºç‰¹å¾å‡½æ•°
            objective_function: ç›®æ ‡å‡½æ•°
            behavior_space: è¡Œä¸ºç©ºé—´
            params: CMA-ESå‚æ•°
        """
        self.dimension = dimension
        self.behavior_function = behavior_function
        self.objective_function = objective_function
        self.behavior_space = behavior_space
        self.params = params or CMAParameters()

        # å†…éƒ¨CMA-ESä¼˜åŒ–å™¨
        self.cmaes = CMAESOptimizer(
            dimension=dimension,
            objective_function=objective_function,
            params=params
        )

        # QDå½’æ¡£
        from .archive import Archive
        from .characterization import ArchitectureMetrics
        self.archive = Archive(behavior_space=behavior_space)

        logger.info(f"ğŸ§¬ CMA-ES QDä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

    def optimize_qd(self,
                     n_iterations: int = 1000,
                     batch_size: int = 10,
                     verbose: bool = True) -> Any:
        """
        è¿è¡ŒQDä¼˜åŒ–

        Args:
            n_iterations: è¿­ä»£æ¬¡æ•°
            batch_size: æ¯æ¬¡è¿­ä»£ç”Ÿæˆçš„ä¸ªä½“æ•°
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯

        Returns:
            å½’æ¡£å¯¹è±¡
        """
        logger.info(f"ğŸš€ å¼€å§‹CMA-ES QDä¼˜åŒ–ï¼Œè¿­ä»£æ¬¡æ•°: {n_iterations}")

        for iteration in range(n_iterations):
            # ç”Ÿæˆä¸€æ‰¹ä¸ªä½“
            population = []
            for _ in range(batch_size):
                # æ‰§è¡ŒCMA-ESä¸€æ­¥
                solution, _ = self.cmaes.step()
                population.append(solution)

            # è¯„ä¼°å¹¶æ’å…¥å½’æ¡£
            for sol in population:
                # è·å–è¡Œä¸ºç‰¹å¾
                behavior = self.behavior_function(sol)

                # è·å–ç›®æ ‡å€¼
                fitness = self.objective_function(sol)

                # åˆ›å»ºæŒ‡æ ‡
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥åˆ›å»ºArchitectureMetrics
                # metrics = ArchitectureMetrics(accuracy=fitness, ...)

                # æ’å…¥å½’æ¡£ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                # self.archive.insert(sol, metrics, generation=iteration)
                pass

            # è¾“å‡ºè¿›åº¦
            if verbose and (iteration + 1) % 10 == 0:
                stats = self.archive.get_statistics()
                logger.info(
                    f"Iteration {iteration + 1}/{n_iterations} | "
                    f"Archive: {stats['size']} | "
                    f"Coverage: {stats['coverage']:.2%}"
                )

        logger.info("âœ… CMA-ES QDä¼˜åŒ–å®Œæˆ")
        return self.archive


def create_cmaes_optimizer(dimension: int,
                           objective_function: Callable[[np.ndarray], float],
                           **kwargs) -> CMAESOptimizer:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºCMA-ESä¼˜åŒ–å™¨

    Args:
        dimension: ä¼˜åŒ–ç»´åº¦
        objective_function: ç›®æ ‡å‡½æ•°
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        CMA-ESä¼˜åŒ–å™¨
    """
    return CMAESOptimizer(dimension, objective_function, **kwargs)


# æµ‹è¯•å‡½æ•°
def test_cmaes():
    """æµ‹è¯•CMA-ESä¼˜åŒ–å™¨"""

    # å®šä¹‰æµ‹è¯•ç›®æ ‡å‡½æ•°ï¼ˆSphereå‡½æ•°ï¼‰
    def sphere_function(x: np.ndarray) -> float:
        return np.sum(x**2)

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = create_cmaes_optimizer(
        dimension=10,
        objective_function=sphere_function,
        params=CMAParameters(population_size=50, sigma=1.0)
    )

    # è¿è¡Œä¼˜åŒ–
    best_solution, best_fitness, info = optimizer.optimize(
        n_iterations=100,
        verbose=True
    )

    print(f"\nBest solution: {best_solution}")
    print(f"Best fitness: {best_fitness}")
    print(f"Convergence rate: {info['best_fitness_history'][-10:]}")


if __name__ == "__main__":
    test_cmaes()
