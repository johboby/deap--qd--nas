"""
åˆ†å¸ƒå¼è®¡ç®—æ¨¡å— (Distributed Computing)
æ”¯æŒå¤šè¿›ç¨‹è¯„ä¼°å’ŒGPUåŠ é€Ÿ
"""

import numpy as np
from typing import List, Dict, Any, Optional, Callable, Tuple
from dataclasses import dataclass
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import multiprocessing as mp
from abc import ABC, abstractmethod
import logging
import time
import os

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    from ray import serve, remote, init as ray_init, get_actor
    RAY_AVAILABLE = True
except ImportError:
    RAY_AVAILABLE = False


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class WorkerConfig:
    """
    å·¥ä½œè¿›ç¨‹é…ç½®

    Args:
        n_workers: å·¥ä½œè¿›ç¨‹æ•°
        use_gpu: æ˜¯å¦ä½¿ç”¨GPU
        gpu_ids: GPU IDåˆ—è¡¨
        use_ray: æ˜¯å¦ä½¿ç”¨Ray
        max_tasks_per_worker: æ¯ä¸ªworkerçš„æœ€å¤§ä»»åŠ¡æ•°
    """
    n_workers: int = None  # Noneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
    use_gpu: bool = False
    gpu_ids: List[int] = None
    use_ray: bool = False
    max_tasks_per_worker: int = 10

    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        if self.n_workers is None:
            self.n_workers = mp.cpu_count()

        if self.use_gpu and not TORCH_AVAILABLE:
            logger.warning("PyTorch not available, GPU acceleration disabled")
            self.use_gpu = False

        if self.use_ray and not RAY_AVAILABLE:
            logger.warning("Ray not available, falling back to multiprocessing")
            self.use_ray = False


class BaseEvaluator(ABC):
    """
    è¯„ä¼°å™¨åŸºç±»
    """

    @abstractmethod
    def evaluate(self, items: List[Any], **kwargs) -> List[Any]:
        """
        è¯„ä¼°ä¸€æ‰¹é¡¹ç›®

        Args:
            items: å¾…è¯„ä¼°çš„é¡¹ç›®åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è¯„ä¼°ç»“æœåˆ—è¡¨
        """
        pass


class SerialEvaluator(BaseEvaluator):
    """
    ä¸²è¡Œè¯„ä¼°å™¨

    å•è¿›ç¨‹é¡ºåºè¯„ä¼°ï¼Œé€‚ç”¨äºå°è§„æ¨¡ä»»åŠ¡ã€‚
    """

    def __init__(self, evaluate_function: Callable[[Any], Any]):
        """
        åˆå§‹åŒ–ä¸²è¡Œè¯„ä¼°å™¨

        Args:
            evaluate_function: è¯„ä¼°å‡½æ•°
        """
        self.evaluate_function = evaluate_function

    def evaluate(self, items: List[Any], **kwargs) -> List[Any]:
        """
        è¯„ä¼°ä¸€æ‰¹é¡¹ç›®

        Args:
            items: å¾…è¯„ä¼°çš„é¡¹ç›®åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è¯„ä¼°ç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸ”„ ä¸²è¡Œè¯„ä¼° {len(items)} ä¸ªé¡¹ç›®")

        results = []
        for i, item in enumerate(items):
            result = self.evaluate_function(item)
            results.append(result)

            if (i + 1) % 10 == 0:
                logger.info(f"  è¿›åº¦: {i + 1}/{len(items)}")

        logger.info(f"âœ… ä¸²è¡Œè¯„ä¼°å®Œæˆ")
        return results


class MultiProcessEvaluator(BaseEvaluator):
    """
    å¤šè¿›ç¨‹è¯„ä¼°å™¨

    ä½¿ç”¨ProcessPoolExecutorè¿›è¡Œå¹¶è¡Œè¯„ä¼°ã€‚
    """

    def __init__(self,
                 evaluate_function: Callable[[Any], Any],
                 config: WorkerConfig):
        """
        åˆå§‹åŒ–å¤šè¿›ç¨‹è¯„ä¼°å™¨

        Args:
            evaluate_function: è¯„ä¼°å‡½æ•°
            config: å·¥ä½œé…ç½®
        """
        self.evaluate_function = evaluate_function
        self.config = config

        logger.info(f"âš¡ åˆå§‹åŒ–å¤šè¿›ç¨‹è¯„ä¼°å™¨")
        logger.info(f"   å·¥ä½œè¿›ç¨‹æ•°: {config.n_workers}")
        logger.info(f"   GPUåŠ é€Ÿ: {config.use_gpu}")

    def evaluate(self, items: List[Any], **kwargs) -> List[Any]:
        """
        è¯„ä¼°ä¸€æ‰¹é¡¹ç›®

        Args:
            items: å¾…è¯„ä¼°çš„é¡¹ç›®åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è¯„ä¼°ç»“æœåˆ—è¡¨
        """
        logger.info(f"âš¡ å¹¶è¡Œè¯„ä¼° {len(items)} ä¸ªé¡¹ç›®ï¼ˆ{self.config.n_workers} ä¸ªè¿›ç¨‹ï¼‰")

        start_time = time.time()

        # åˆ›å»ºç»“æœåˆ—è¡¨ï¼ˆä¿æŒé¡ºåºï¼‰
        results = [None] * len(items)

        # åˆ›å»ºProcessPoolExecutor
        with ProcessPoolExecutor(max_workers=self.config.n_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {}
            for i, item in enumerate(items):
                future = executor.submit(self._worker, item, self.config)
                future_to_index[future] = i

            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    result = future.result()
                    results[index] = result
                    completed += 1

                    if completed % max(1, len(items) // 10) == 0:
                        logger.info(f"  è¿›åº¦: {completed}/{len(items)}")

                except Exception as e:
                    logger.error(f"  ä»»åŠ¡ {index} å¤±è´¥: {e}")
                    results[index] = None

        elapsed = time.time() - start_time
        logger.info(f"âœ… å¹¶è¡Œè¯„ä¼°å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}s")

        return results

    def _worker(self, item: Any, config: WorkerConfig) -> Any:
        """
        å·¥ä½œè¿›ç¨‹å‡½æ•°

        Args:
            item: å¾…è¯„ä¼°çš„é¡¹ç›®
            config: å·¥ä½œé…ç½®

        Returns:
            è¯„ä¼°ç»“æœ
        """
        # è®¾ç½®GPU
        if config.use_gpu and config.gpu_ids:
            import os
            gpu_id = os.getpid() % len(config.gpu_ids)
            os.environ['CUDA_VISIBLE_DEVICES'] = str(config.gpu_ids[gpu_id])

        # æ‰§è¡Œè¯„ä¼°
        return self.evaluate_function(item)


class GPUAcceleratedEvaluator(BaseEvaluator):
    """
    GPUåŠ é€Ÿè¯„ä¼°å™¨

    ä½¿ç”¨GPUè¿›è¡ŒåŠ é€Ÿè¯„ä¼°ã€‚
    """

    def __init__(self,
                 evaluate_function: Callable[[Any, str], Any],
                 config: WorkerConfig):
        """
        åˆå§‹åŒ–GPUåŠ é€Ÿè¯„ä¼°å™¨

        Args:
            evaluate_function: è¯„ä¼°å‡½æ•°ï¼ˆéœ€è¦deviceå‚æ•°ï¼‰
            config: å·¥ä½œé…ç½®
        """
        if not TORCH_AVAILABLE:
            raise ImportError("PyTorch is required for GPU acceleration")

        self.evaluate_function = evaluate_function
        self.config = config

        # æ£€æŸ¥GPUå¯ç”¨æ€§
        if torch.cuda.is_available():
            self.n_gpus = torch.cuda.device_count()
            logger.info(f"ğŸ® æ£€æµ‹åˆ° {self.n_gpus} ä¸ªGPU")
        else:
            logger.warning("æœªæ£€æµ‹åˆ°CUDAï¼ŒGPUåŠ é€Ÿä¸å¯ç”¨")
            self.n_gpus = 0

        # åˆ†é…GPU
        if config.use_gpu and config.gpu_ids:
            self.allocated_gpus = config.gpu_ids
        elif config.use_gpu and self.n_gpus > 0:
            self.allocated_gpus = list(range(self.n_gpus))
        else:
            self.allocated_gpus = []

    def evaluate(self, items: List[Any], **kwargs) -> List[Any]:
        """
        è¯„ä¼°ä¸€æ‰¹é¡¹ç›®ï¼ˆä½¿ç”¨GPUï¼‰

        Args:
            items: å¾…è¯„ä¼°çš„é¡¹ç›®åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è¯„ä¼°ç»“æœåˆ—è¡¨
        """
        if not self.allocated_gpus:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„GPUï¼Œå›é€€åˆ°CPUè¯„ä¼°")
            return self._evaluate_cpu(items)

        logger.info(f"ğŸ® GPUè¯„ä¼° {len(items)} ä¸ªé¡¹ç›®ï¼ˆ{len(self.allocated_gpus)} ä¸ªGPUï¼‰")

        start_time = time.time()

        # åˆ†é…ä»»åŠ¡åˆ°GPU
        results = self._evaluate_on_gpus(items)

        elapsed = time.time() - start_time
        logger.info(f"âœ… GPUè¯„ä¼°å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}s")

        return results

    def _evaluate_cpu(self, items: List[Any]) -> List[Any]:
        """CPUè¯„ä¼°"""
        results = []
        for item in items:
            result = self.evaluate_function(item, 'cpu')
            results.append(result)
        return results

    def _evaluate_on_gpus(self, items: List[Any]) -> List[Any]:
        """åœ¨GPUä¸Šè¯„ä¼°"""
        n_gpus = len(self.allocated_gpus)

        # ä¸ºæ¯ä¸ªGPUåˆ›å»ºçº¿ç¨‹æ± 
        with ThreadPoolExecutor(max_workers=n_gpus) as executor:
            futures = []

            for i, item in enumerate(items):
                # åˆ†é…åˆ°GPU
                gpu_id = self.allocated_gpus[i % n_gpus]
                device = f'cuda:{gpu_id}'

                future = executor.submit(self.evaluate_function, item, device)
                futures.append((future, i))

            # æ”¶é›†ç»“æœ
            results = [None] * len(items)
            completed = 0

            for future, index in futures:
                try:
                    result = future.result()
                    results[index] = result
                    completed += 1

                    if completed % max(1, len(items) // 10) == 0:
                        logger.info(f"  è¿›åº¦: {completed}/{len(items)}")

                except Exception as e:
                    logger.error(f"  GPUä»»åŠ¡ {index} å¤±è´¥: {e}")
                    results[index] = None

        return results


class DistributedNASOptimizer:
    """
    åˆ†å¸ƒå¼NASä¼˜åŒ–å™¨

    æ”¯æŒå¤šè¿›ç¨‹å’ŒGPUåŠ é€Ÿçš„NASä¼˜åŒ–ã€‚
    """

    def __init__(self,
                 optimizer: Any,  # QDNASOptimizeræˆ–å…¶ä»–ä¼˜åŒ–å™¨
                 evaluator: BaseEvaluator,
                 batch_size: int = 100):
        """
        åˆå§‹åŒ–åˆ†å¸ƒå¼NASä¼˜åŒ–å™¨

        Args:
            optimizer: åŸºç¡€ä¼˜åŒ–å™¨
            evaluator: è¯„ä¼°å™¨
            batch_size: æ‰¹å¤„ç†å¤§å°
        """
        self.optimizer = optimizer
        self.evaluator = evaluator
        self.batch_size = batch_size

        logger.info(f"ğŸš€ åˆ†å¸ƒå¼NASä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ‰¹å¤„ç†å¤§å°: {batch_size}")

    def optimize_distributed(self,
                           n_iterations: int = 1000,
                           verbose: bool = True) -> Tuple[Any, List]:
        """
        åˆ†å¸ƒå¼ä¼˜åŒ–

        Args:
            n_iterations: è¿­ä»£æ¬¡æ•°
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯

        Returns:
            (archive, pareto_front)
        """
        logger.info(f"ğŸš€ å¼€å§‹åˆ†å¸ƒå¼ä¼˜åŒ–ï¼Œè¿­ä»£æ¬¡æ•°: {n_iterations}")

        # åˆå§‹åŒ–
        self.optimizer.initialize()

        for iteration in range(n_iterations):
            # ç”Ÿæˆä¸€æ‰¹å€™é€‰æ¶æ„
            candidates = self._generate_candidates(self.batch_size)

            # åˆ†å¸ƒå¼è¯„ä¼°
            metrics_list = self.evaluator.evaluate(candidates)

            # å¤„ç†è¯„ä¼°ç»“æœ
            self._process_evaluation_results(candidates, metrics_list, iteration)

            # è¾“å‡ºè¿›åº¦
            if verbose and (iteration + 1) % 10 == 0:
                stats = self.optimizer.get_statistics()
                logger.info(
                    f"Iteration {iteration + 1}/{n_iterations} | "
                    f"Archive: {stats['size']} | "
                    f"Coverage: {stats['coverage']:.2%} | "
                    f"Best: {stats['best_fitness']:.4f}"
                )

        logger.info("âœ… åˆ†å¸ƒå¼ä¼˜åŒ–å®Œæˆ")

        # è¿”å›ç»“æœ
        archive = self.optimizer.get_archive()
        pareto_front = self.optimizer.get_pareto_front()

        return archive, pareto_front

    def _generate_candidates(self, batch_size: int) -> List[Any]:
        """ç”Ÿæˆå€™é€‰æ¶æ„"""
        candidates = []
        for _ in range(batch_size):
            if hasattr(self.optimizer, 'search_space'):
                candidate = self.optimizer.search_space.random_sample()
            else:
                candidate = self.optimizer.search_space.random_sample()

            candidates.append(candidate)

        return candidates

    def _process_evaluation_results(self,
                                     candidates: List[Any],
                                     metrics_list: List[Any],
                                     generation: int):
        """å¤„ç†è¯„ä¼°ç»“æœ"""
        for candidate, metrics in zip(candidates, metrics_list):
            if metrics is not None:
                if hasattr(self.optimizer, 'archive'):
                    self.optimizer.archive.insert(
                        architecture=candidate,
                        metrics=metrics,
                        generation=generation
                    )
                elif hasattr(self.optimizer, 'optimizer') and hasattr(self.optimizer.optimizer, 'archive'):
                    self.optimizer.optimizer.archive.insert(
                        architecture=candidate,
                        metrics=metrics,
                        generation=generation
                    )


class BatchProcessor:
    """
    æ‰¹å¤„ç†å™¨

    é«˜æ•ˆå¤„ç†å¤§æ‰¹é‡ä»»åŠ¡ã€‚
    """

    def __init__(self,
                 process_function: Callable[[List[Any]], List[Any]],
                 batch_size: int = 100,
                 n_workers: int = None):
        """
        åˆå§‹åŒ–æ‰¹å¤„ç†å™¨

        Args:
            process_function: å¤„ç†å‡½æ•°
            batch_size: æ‰¹å¤„ç†å¤§å°
            n_workers: å·¥ä½œè¿›ç¨‹æ•°
        """
        self.process_function = process_function
        self.batch_size = batch_size
        self.n_workers = n_workers or mp.cpu_count()

    def process(self, items: List[Any]) -> List[Any]:
        """
        å¤„ç†ä¸€æ‰¹é¡¹ç›®

        Args:
            items: å¾…å¤„ç†çš„é¡¹ç›®åˆ—è¡¨

        Returns:
            å¤„ç†ç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸ“¦ å¤„ç† {len(items)} ä¸ªé¡¹ç›®ï¼ˆæ‰¹å¤§å°: {self.batch_size}ï¼‰")

        results = []
        batches = self._create_batches(items, self.batch_size)

        for i, batch in enumerate(batches):
            batch_result = self.process_function(batch)
            results.extend(batch_result)

            if (i + 1) % 10 == 0:
                logger.info(f"  æ‰¹æ¬¡: {i + 1}/{len(batches)}")

        logger.info(f"âœ… æ‰¹å¤„ç†å®Œæˆ")
        return results

    def _create_batches(self, items: List[Any], batch_size: int) -> List[List[Any]]:
        """åˆ›å»ºæ‰¹æ¬¡"""
        n_batches = (len(items) + batch_size - 1) // batch_size
        return [items[i * batch_size:(i + 1) * batch_size] for i in range(n_batches)]


def create_evaluator(evaluate_function: Callable,
                     use_multiprocessing: bool = False,
                     use_gpu: bool = False,
                     n_workers: Optional[int] = None) -> BaseEvaluator:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºè¯„ä¼°å™¨

    Args:
        evaluate_function: è¯„ä¼°å‡½æ•°
        use_multiprocessing: æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
        use_gpu: æ˜¯å¦ä½¿ç”¨GPU
        n_workers: å·¥ä½œè¿›ç¨‹æ•°

    Returns:
        è¯„ä¼°å™¨
    """
    config = WorkerConfig(
        n_workers=n_workers,
        use_gpu=use_gpu
    )

    if use_gpu and TORCH_AVAILABLE:
        return GPUAcceleratedEvaluator(evaluate_function, config)
    elif use_multiprocessing:
        return MultiProcessEvaluator(evaluate_function, config)
    else:
        return SerialEvaluator(evaluate_function)


__all__ = [
    'WorkerConfig',
    'BaseEvaluator',
    'SerialEvaluator',
    'MultiProcessEvaluator',
    'GPUAcceleratedEvaluator',
    'DistributedNASOptimizer',
    'BatchProcessor',
    'create_evaluator',
]
