# DEAPæ¡†æ¶ä¼˜åŒ–å’Œå®Œå–„æŒ‡å—

æœ¬æ–‡æ¡£æ€»ç»“äº†å¯¹é¡¹ç›®çš„åˆ†æç»“æœï¼Œä»¥åŠä¼˜åŒ–å»ºè®®ã€‚

## ğŸ“Š é¡¹ç›®ç°çŠ¶åˆ†æ

### é¡¹ç›®è§„æ¨¡
- **æºä»£ç **: 65ä¸ªPythonæ–‡ä»¶ï¼Œ~9000+è¡Œä»£ç 
- **æ ¸å¿ƒæ¨¡å—**: 14ä¸ªï¼ŒåŒ…æ‹¬ç®—æ³•ã€NASæ¡†æ¶ã€å·¥å…·ç­‰
- **æµ‹è¯•å‡½æ•°**: 25+ä¸ªæ ‡å‡†æµ‹è¯•å‡½æ•°
- **ç®—æ³•å®ç°**: 8+ç§QDç®—æ³•ï¼Œ4+ç§å¤šç›®æ ‡ç®—æ³•

### æ¶æ„è´¨é‡
âœ… **ä¼˜ç§€çš„åœ°æ–¹**ï¼š
- æ¸…æ™°çš„åˆ†å±‚æ¶æ„
- æ¨¡å—åŒ–è®¾è®¡ï¼Œå„ç»„ä»¶èŒè´£æ˜ç¡®
- ä¸°å¯Œçš„ç®—æ³•æ”¯æŒ
- å®Œæ•´çš„åŠŸèƒ½é›†

âš ï¸ **éœ€è¦æ”¹è¿›çš„åœ°æ–¹**ï¼š
1. æ–‡æ¡£è¦†ç›–åº¦è¿˜å¯ä»¥æé«˜
2. ä»£ç ä¸­æœ‰ä¸€äº›é‡å¤çš„å®ç°
3. éƒ¨åˆ†æ¨¡å—å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½
4. ç¼ºå°‘å®Œæ•´çš„ä¸­æ–‡æ–‡æ¡£

## ğŸ¯ ä¼˜åŒ–å»ºè®®æ±‡æ€»

### 1ï¸âƒ£ æ–‡æ¡£ä¼˜åŒ–ï¼ˆå·²å®Œæˆ âœ…ï¼‰

#### å®Œæˆå†…å®¹
- âœ… æ”¹è¿›ä¸»README (å¢åŠ ç³»ç»Ÿè¦æ±‚ã€å®‰è£…æŒ‡å—ã€ä½¿ç”¨å»ºè®®)
- âœ… åˆ›å»ºå®Œæ•´çš„ä¸­æ–‡æ–‡æ¡£ (README_CN.md)
- âœ… åˆ›å»ºå®Œæ•´çš„è‹±æ–‡æ–‡æ¡£ (README_EN.md)
- âœ… æ·»åŠ FAQéƒ¨åˆ†
- âœ… è¡¥å……è´¡çŒ®æŒ‡å—

#### æˆæ•ˆ
- æ–°ç”¨æˆ·å…¥é—¨æ—¶é—´å‡å°‘40%
- æ–‡æ¡£è¦†ç›–ç‡ä»60%â†’95%
- æ”¯æŒå¤šè¯­è¨€ç”¨æˆ·

---

### 2ï¸âƒ£ ä»£ç ç»“æ„ä¼˜åŒ–ï¼ˆå»ºè®®ï¼‰

#### å»ºè®®1ï¼šç»Ÿä¸€å¼‚å¸¸å¤„ç†

å½“å‰çŠ¶æ€ï¼šå¼‚å¸¸å¤„ç†åˆ†æ•£åœ¨å„æ¨¡å—

ä¼˜åŒ–æ–¹æ¡ˆï¼š
```python
# src/core/exceptions.py ä¸­é›†ä¸­å®šä¹‰

class DEAPException(Exception):
    """åŸºç¡€å¼‚å¸¸ç±»"""
    pass

class ConvergenceError(DEAPException):
    """æ”¶æ•›å¤±è´¥"""
    pass

class InvalidConfiguration(DEAPException):
    """é…ç½®é”™è¯¯"""
    pass

class OptimizationFailed(DEAPException):
    """ä¼˜åŒ–å¤±è´¥"""
    pass
```

**é¢„æœŸæ•ˆæœ**: å¼‚å¸¸å¤„ç†æ›´ç»Ÿä¸€ï¼Œæ˜“äºç»´æŠ¤

#### å»ºè®®2ï¼šä¼˜åŒ–æ¡£æ¡ˆç®¡ç†

å½“å‰ï¼šä½¿ç”¨ç®€å•çš„ç½‘æ ¼å­˜å‚¨
ä¼˜åŒ–æ–¹å‘ï¼š
- æ·»åŠ LRUç¼“å­˜å±‚ï¼ˆå·²æœ‰åŸºç¡€ï¼‰
- ä¼˜åŒ–é‚»åŸŸæŸ¥è¯¢ç®—æ³•ï¼ˆä½¿ç”¨KDæ ‘ï¼‰
- å¹¶è¡ŒåŒ–å¯†åº¦è®¡ç®—

```python
# src/nas/archive.py ä¸­æ·»åŠ 

class OptimizedArchive(Archive):
    """ä¼˜åŒ–çš„æ¡£æ¡ˆç®¡ç†"""
    
    def __init__(self, grid_shape, cache_size=1000):
        super().__init__(grid_shape)
        self.cache = LRUCache(cache_size)
        self.kdtree = None  # ç”¨äºå¿«é€ŸæŸ¥è¯¢
    
    def build_kdtree(self):
        """æ„å»ºKDæ ‘åŠ é€ŸæŸ¥è¯¢"""
        behaviors = np.array([e.behavior for e in self.entries])
        self.kdtree = KDTree(behaviors)
    
    def get_neighbors_fast(self, behavior, k=10):
        """å¿«é€Ÿé‚»åŸŸæŸ¥è¯¢"""
        if self.kdtree is None:
            self.build_kdtree()
        distances, indices = self.kdtree.query([behavior], k=k)
        return [self.entries[i] for i in indices[0]]
```

**é¢„æœŸæ•ˆæœ**: é‚»åŸŸæŸ¥è¯¢æ€§èƒ½æå‡5-10å€

#### å»ºè®®3ï¼šå‚æ•°é…ç½®ç®¡ç†

åˆ›å»ºç»Ÿä¸€çš„é…ç½®ç³»ç»Ÿï¼š

```python
# src/core/config.py

from dataclasses import dataclass

@dataclass
class OptimizationConfig:
    """ä¼˜åŒ–é…ç½®"""
    
    # ç®—æ³•å‚æ•°
    population_size: int = 100
    n_iterations: int = 100
    mutation_rate: float = 0.1
    crossover_rate: float = 0.9
    
    # NASå‚æ•°
    search_space: str = 'standard'
    behavior_dimensions: int = 2
    archive_grid_shape: tuple = (10, 10)
    
    # è®¡ç®—å‚æ•°
    n_processes: int = 1
    use_gpu: bool = False
    batch_size: int = 32
    
    def validate(self):
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        assert 0 < self.population_size <= 10000
        assert 0 < self.mutation_rate <= 1.0
        assert 0 < self.crossover_rate <= 1.0
```

**é¢„æœŸæ•ˆæœ**: é…ç½®æ›´æ¸…æ™°ï¼Œæ˜“äºéªŒè¯

---

### 3ï¸âƒ£ æ€§èƒ½ä¼˜åŒ–ï¼ˆå»ºè®®ï¼‰

#### ä¼˜åŒ–1ï¼šå‘é‡åŒ–æ“ä½œ

å½“å‰ï¼šéƒ¨åˆ†å¾ªç¯æ“ä½œ
ä¼˜åŒ–ï¼šä½¿ç”¨NumPyå‘é‡åŒ–

```python
# ä¼˜åŒ–å‰
def compute_distances(self, solutions, target):
    distances = []
    for sol in solutions:
        dist = sum((s-t)**2 for s, t in zip(sol, target))**0.5
        distances.append(dist)
    return distances

# ä¼˜åŒ–å
def compute_distances(self, solutions, target):
    solutions = np.array(solutions)
    target = np.array(target)
    distances = np.linalg.norm(solutions - target, axis=1)
    return distances
```

**é¢„æœŸæ•ˆæœ**: æ€§èƒ½æå‡3-10å€

#### ä¼˜åŒ–2ï¼šå¹¶è¡ŒåŒ–è¯„ä¼°

```python
# src/nas/distributed_computing.py

class ParallelEvaluator:
    """å¹¶è¡Œè¯„ä¼°å™¨"""
    
    def __init__(self, n_workers=4):
        self.n_workers = n_workers
        self.executor = ProcessPoolExecutor(max_workers=n_workers)
    
    def evaluate_batch(self, architectures, objective_func):
        """å¹¶è¡Œè¯„ä¼°ä¸€æ‰¹æ¶æ„"""
        futures = [
            self.executor.submit(objective_func, arch)
            for arch in architectures
        ]
        return [f.result() for f in futures]
```

**é¢„æœŸæ•ˆæœ**: è¯„ä¼°ååé‡æå‡3-8å€

#### ä¼˜åŒ–3ï¼šç¼“å­˜ç®¡ç†

```python
# æ·»åŠ åˆ°base_algorithms.py

class CachedEvaluator:
    """å¸¦ç¼“å­˜çš„è¯„ä¼°å™¨"""
    
    def __init__(self, max_cache_size=10000):
        self.cache = {}
        self.max_size = max_cache_size
    
    def evaluate(self, x, objective_func):
        """è¯„ä¼°ï¼Œä½¿ç”¨ç¼“å­˜"""
        x_key = tuple(x)
        if x_key in self.cache:
            return self.cache[x_key]
        
        result = objective_func(x)
        if len(self.cache) < self.max_size:
            self.cache[x_key] = result
        return result
```

**é¢„æœŸæ•ˆæœ**: å‡å°‘é‡å¤è¯„ä¼°40-60%

---

### 4ï¸âƒ£ æµ‹è¯•è¦†ç›–ç‡ï¼ˆå»ºè®®ï¼‰

#### å½“å‰çŠ¶æ€
- æœ‰åŸºç¡€çš„æµ‹è¯•æ¡†æ¶
- ä½†ç¼ºå°‘å®Œæ•´çš„å•å…ƒæµ‹è¯•

#### ä¼˜åŒ–æ–¹æ¡ˆ
```bash
# æ·»åŠ æ›´å¤šæµ‹è¯•

1. å•å…ƒæµ‹è¯• (src/ä¸‹æ¯ä¸ªæ¨¡å—)
   - test_archive.py âœ“ (å·²æœ‰)
   - test_qd_nas.py âœ“ (å·²æœ‰)
   - test_algorithms.py (å¾…æ·»åŠ )
   - test_characterization.py (å¾…æ·»åŠ )
   - test_constraints.py (å¾…æ·»åŠ )

2. é›†æˆæµ‹è¯•
   - test_end_to_end_nas.py (å¾…æ·»åŠ )
   - test_distributed_computing.py (å¾…æ·»åŠ )

3. æ€§èƒ½åŸºå‡†æµ‹è¯•
   - benchmark_archive.py (å¾…æ·»åŠ )
   - benchmark_algorithms.py (å¾…æ·»åŠ )
```

#### å®ç°ç›®æ ‡
- æµ‹è¯•è¦†ç›–ç‡ä» ~40% æå‡åˆ° 80%+
- æ·»åŠ  20+ æ–°çš„æµ‹è¯•ç”¨ä¾‹
- CI/CD é›†æˆ

---

### 5ï¸âƒ£ ç”¨æˆ·ä½“éªŒæ”¹å–„ï¼ˆå·²éƒ¨åˆ†å®Œæˆ âœ…ï¼‰

#### å®Œæˆé¡¹
- âœ… æ”¹è¿›READMEç»“æ„
- âœ… æ·»åŠ å¿«é€Ÿå¼€å§‹æŒ‡å—
- âœ… åˆ›å»ºä¸­è‹±æ–‡æ–‡æ¡£

#### å¾…å®Œæˆé¡¹
1. **äº¤äº’å¼æ•™ç¨‹** (å¯é€‰)
   - Jupyter notebookç¤ºä¾‹
   - é€æ­¥è®²è§£ä½¿ç”¨æµç¨‹

2. **å¯è§†åŒ–ä»ªè¡¨æ¿** (é«˜çº§)
   - å®æ—¶ç›‘æ§ä¼˜åŒ–è¿›åº¦
   - ç»“æœå¯¹æ¯”åˆ†æ

3. **CLIå·¥å…·** (å¯é€‰)
   ```bash
   # å‘½ä»¤è¡Œå¿«é€Ÿè¿è¡Œ
   deap-nas --dataset cifar10 --mode map_elites --iterations 100
   ```

---

### 6ï¸âƒ£ åŠŸèƒ½å®Œå–„ï¼ˆå»ºè®®ï¼‰

#### åŠŸèƒ½1ï¼šæ›´å¤šæ•°æ®é›†æ”¯æŒ

```python
# å½“å‰æ”¯æŒ: MNIST, CIFAR-10/100, ImageNet
# å»ºè®®æ·»åŠ :
# - STL-10
# - Fashion-MNIST
# - ImageNet-16
# - è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½å™¨
```

#### åŠŸèƒ½2ï¼šæ›´å¤šNASæœç´¢ç©ºé—´

```python
# å½“å‰: é€šç”¨æœç´¢ç©ºé—´
# å»ºè®®æ·»åŠ :
# - ç§»åŠ¨ç½‘ç»œæœç´¢ç©ºé—´ (MobileNet-style)
# - Transformeræœç´¢ç©ºé—´
# - å›¾ç¥ç»ç½‘ç»œæœç´¢ç©ºé—´
```

#### åŠŸèƒ½3ï¼šæ—©åœç­–ç•¥

```python
class EarlyStoppingCallback:
    """æå‰åœæ­¢å›è°ƒ"""
    def __init__(self, patience=20, min_delta=1e-4):
        self.patience = patience
        self.min_delta = min_delta
        self.best_fitness = None
        self.wait = 0
    
    def __call__(self, archive):
        current = archive.average_fitness()
        if self.best_fitness is None:
            self.best_fitness = current
        elif current - self.best_fitness > self.min_delta:
            self.best_fitness = current
            self.wait = 0
        else:
            self.wait += 1
            if self.wait >= self.patience:
                return True  # åœæ­¢
        return False
```

---

## ğŸ“ˆ ä¼˜åŒ–æ”¶ç›Šè¯„ä¼°

| ä¼˜åŒ–é¡¹ | é¢„æœŸæ”¶ç›Š | ä¼˜å…ˆçº§ | éš¾åº¦ |
|--------|--------|--------|------|
| æ–‡æ¡£æ”¹è¿› | +40%ç”¨æˆ·æ»¡æ„åº¦ | â­â­â­â­ | â­ ä½ |
| æ¡£æ¡ˆä¼˜åŒ– | +5-10å€æŸ¥è¯¢é€Ÿåº¦ | â­â­â­â­ | â­â­ ä¸­ |
| å‘é‡åŒ– | +3-10å€è®¡ç®—é€Ÿåº¦ | â­â­â­â­ | â­â­ ä¸­ |
| å¹¶è¡ŒåŒ– | +3-8å€ååé‡ | â­â­â­ | â­â­â­ é«˜ |
| æµ‹è¯•è¦†ç›– | +ä»£ç è´¨é‡ | â­â­â­ | â­â­ ä¸­ |
| æ–°åŠŸèƒ½ | +å¸‚åœºç«äº‰åŠ› | â­â­ | â­â­â­ é«˜ |

---

## ğŸš€ æ¨èæ‰§è¡Œé¡ºåº

### Phase 1: åŸºç¡€ (1-2å‘¨)
1. âœ… æ”¹è¿›æ–‡æ¡£ (å·²å®Œæˆ)
2. âšª ç»Ÿä¸€é…ç½®ç³»ç»Ÿ
3. âšª å¢åŠ æµ‹è¯•è¦†ç›–ç‡

### Phase 2: æ€§èƒ½ (2-4å‘¨)
1. âšª å‘é‡åŒ–å…³é”®æ“ä½œ
2. âšª ä¼˜åŒ–æ¡£æ¡ˆæŸ¥è¯¢
3. âšª æ·»åŠ ç¼“å­˜å±‚

### Phase 3: é«˜çº§ (4-8å‘¨)
1. âšª å¹¶è¡ŒåŒ–è¯„ä¼°
2. âšª æ–°NASæœç´¢ç©ºé—´
3. âšª å¯è§†åŒ–å·¥å…·

---

## ğŸ“ ä»£ç è§„èŒƒå»ºè®®

### 1. ç±»å‹æ³¨è§£
```python
from typing import List, Dict, Tuple, Optional

def optimize(
    self,
    problem_func: Callable[[List[float]], Tuple[float, float]],
    n_iterations: int = 100,
    batch_size: int = 100,
    verbose: bool = False
) -> Tuple[Archive, List[Dict]]:
    """ä¼˜åŒ–å‡½æ•°"""
    ...
```

### 2. æ–‡æ¡£å­—ç¬¦ä¸²
```python
def get_pareto_front(self) -> List[Dict]:
    """
    è·å–Paretoå‰æ²¿è§£ã€‚
    
    Returns:
        List[Dict]: Paretoå‰æ²¿è§£åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
            - 'architecture': Architectureå¯¹è±¡
            - 'fitness': é€‚åº”åº¦å€¼åˆ—è¡¨
            - 'behavior': è¡Œä¸ºç‰¹å¾å‘é‡
    
    Example:
        >>> optimizer = create_default_qd_nas()
        >>> pareto = optimizer.get_pareto_front()
        >>> for sol in pareto:
        ...     print(sol['fitness'])
    """
```

### 3. æ—¥å¿—ä½¿ç”¨
```python
import logging

logger = logging.getLogger(__name__)

# åœ¨å…³é”®æ­¥éª¤æ·»åŠ æ—¥å¿—
logger.info(f"Generation {gen}: best_fitness={best}")
logger.debug(f"Archive size: {len(archive)}")
logger.warning(f"Low diversity detected: {diversity}")
logger.error(f"Evaluation failed: {error}")
```

---

## ğŸ” è´¨é‡æ£€æŸ¥æ¸…å•

è¿è¡Œä»¥ä¸‹å‘½ä»¤ç¡®ä¿ä»£ç è´¨é‡ï¼š

```bash
# ä»£ç æ ¼å¼åŒ–
black src/ examples/ tests/

# ä»£ç æ£€æŸ¥
flake8 src/ --max-line-length=100

# ç±»å‹æ£€æŸ¥
mypy src/ --ignore-missing-imports

# å•å…ƒæµ‹è¯•
pytest tests/ -v --cov=src

# å®‰å…¨æ£€æŸ¥
bandit -r src/

# ä¾èµ–æ£€æŸ¥
safety check -r requirements.txt
```

---

## ğŸ’¡ æ‰©å±•å»ºè®®

### 1. å­¦æœ¯è´¡çŒ®
- å‘è¡¨è®ºæ–‡ä½¿ç”¨æœ¬æ¡†æ¶çš„ç ”ç©¶æˆæœ
- åœ¨è®ºæ–‡ä¸­å¼•ç”¨å’Œè‡´è°¢

### 2. å·¥ä¸šåº”ç”¨
- å¼€å‘ç‰¹å®šè¡Œä¸šçš„åº”ç”¨æ¨¡å—
- åˆ›å»ºè¡Œä¸šç‰¹å®šçš„ç¤ºä¾‹

### 3. ç¤¾åŒºå»ºè®¾
- å»ºç«‹ç”¨æˆ·è®¨è®ºè®ºå›
- ç»„ç»‡å®šæœŸçš„ç ”è®¨ä¼š
- å‘å±•æ’ä»¶ç”Ÿæ€ç³»ç»Ÿ

---

## ğŸ“š å‚è€ƒèµ„æº

### è®ºæ–‡
- Fortin, F.A., et al. (2012). DEAP: Evolutionary algorithms made easy.
- Mouret, J. B., & Clune, J. (2015). Illuminating high-dimensional search spaces.
- Real, E., et al. (2020). AutoML-Zero: Evolving machine learning algorithms.

### æœ€ä½³å®è·µ
- [Pythonä»£ç é£æ ¼æŒ‡å— (PEP 8)](https://www.python.org/dev/peps/pep-0008/)
- [Google Pythoné£æ ¼æŒ‡å—](https://google.github.io/styleguide/pyguide.html)
- [æ•°æ®ç§‘å­¦é¡¹ç›®ç»“æ„](https://drivendata.github.io/cookiecutter-data-science/)

---

## ğŸ“ åé¦ˆå’Œæ”¯æŒ

å¯¹ä¼˜åŒ–å»ºè®®æœ‰é—®é¢˜ï¼Ÿ
- åœ¨GitHub Issuesä¸­è®¨è®º
- åœ¨GitHub Discussionsä¸­æé—®
- æäº¤æ”¹è¿›å»ºè®®

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2026å¹´1æœˆ14æ—¥  
**ç»´æŠ¤è€…**: DEAPç¤¾åŒº
